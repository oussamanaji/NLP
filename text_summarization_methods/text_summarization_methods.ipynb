{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Text Summarization Methods in NLP\n",
        "\n",
        "Author: Mohamed Oussama NAJI\n",
        "Date: March 20th, 2024"
      ],
      "metadata": {
        "id": "7cyfMG5Ktd5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, I will explore various Natural Language Processing (NLP) methods for text summarization. My goal is to generate concise summaries from a longer piece of text, specifically an article discussing neural networks. I will compare several summarization techniques, including Gensim, Summa, TextRank, LexRank, Luhn, LSA, BART, PEGASUS, and T5, to determine which method produces the most coherent and informative summary. By analyzing the outputs of these different approaches, I aim to gain insights into their effectiveness and suitability for summarization tasks in NLP.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Installation and Setup](#installation-setup)\n",
        "2. [Importing Libraries](#importing-libraries)\n",
        "3. [Text Extraction](#text-extraction)\n",
        "4. [Summarization with Transformers](#summarization-transformers)\n",
        "5. [Summarization with Sumy](#summarization-sumy)\n",
        "6. [Execution and Results](#execution-results)\n",
        "7. [Conclusion](#conclusion)"
      ],
      "metadata": {
        "id": "kBwvka10t2cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and Setup <a id=\"installation-setup\"></a>\n",
        "\n",
        "Installing the necessary libraries and modifying the relevant packages.\n"
      ],
      "metadata": {
        "id": "BmT1orTCt8IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "!pip install gensim==3.6.0\n",
        "!pip install summa\n",
        "!sed -i 's/from collections import Mapping/from collections.abc import Mapping/g' /usr/local/lib/python3.10/dist-packages/gensim/corpora/dictionary.py\n",
        "!sed -i 's/from collections.abc import Mapping, defaultdict/from collections.abc import Mapping\\nfrom collections import defaultdict/g' /usr/local/lib/python3.10/dist-packages/gensim/corpora/dictionary.py\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "VKkyhJXEuBGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Extraction <a id=\"text-extraction\"></a>\n"
      ],
      "metadata": {
        "id": "Q0u35YdPuGNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to extract the text using a user agent and BeautifulSoup.\n"
      ],
      "metadata": {
        "id": "Z0WXU3cduG_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_medium(url):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        article_text = ' '.join([p.text for p in soup.find_all('p')])\n",
        "        return article_text\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "W6qQpbXguIyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization with Transformers <a id=\"summarization-transformers\"></a>\n"
      ],
      "metadata": {
        "id": "kVBYaYrsuLNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization function for transformer models."
      ],
      "metadata": {
        "id": "j2EflllHuSFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_transformers(text, model, tokenizer, max_length=1024, min_length=40):\n",
        "    model_max_length = tokenizer.model_max_length\n",
        "    max_length = min(max_length, model_max_length)\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "qEmS_SEquTxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization with Sumy <a id=\"summarization-sumy\"></a>"
      ],
      "metadata": {
        "id": "V0z6EA1QuUu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumy summarization function."
      ],
      "metadata": {
        "id": "WkiC-piwuWwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_sumy(url):\n",
        "    parser = HtmlParser.from_url(url, Tokenizer(\"english\"))\n",
        "    doc = parser.document\n",
        "\n",
        "    summarizers = [TextRankSummarizer(), LexRankSummarizer(), LuhnSummarizer(), LsaSummarizer()]\n",
        "    summaries = {}\n",
        "    for summarizer in summarizers:\n",
        "        summary = summarizer(doc, 5)\n",
        "        summaries[summarizer.__class__.__name__] = ' '.join([sentence.__str__() for sentence in summary])\n",
        "    return summaries"
      ],
      "metadata": {
        "id": "b_kqD1HAuYkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution and Results <a id=\"execution-results\"></a>"
      ],
      "metadata": {
        "id": "mEV3mLfruZgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the URL and extracting the text.\n"
      ],
      "metadata": {
        "id": "PQg22NAnuaro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7\"\n",
        "\n",
        "article_text = extract_text_from_medium(url)"
      ],
      "metadata": {
        "id": "heSmds4zucrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing summarizations.\n"
      ],
      "metadata": {
        "id": "M7PBYWzquexw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if article_text:\n",
        "    # Gensim summarization\n",
        "    print(\"Gensim Summary:\", gensim_summarize(article_text, word_count=200))\n",
        "    print()\n",
        "\n",
        "    # Summa summarization\n",
        "    print(\"Summa Summary:\", summa_summarizer.summarize(article_text, ratio=0.1))\n",
        "    print()\n",
        "\n",
        "    # Sumy summarizations\n",
        "    sumy_summaries = summarize_with_sumy(url)\n",
        "    for name, summary in sumy_summaries.items():\n",
        "        print(f\"{name} Summary:\", summary)\n",
        "        print()\n",
        "\n",
        "    # BART summarization\n",
        "    bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    print(\"BART Summary:\", summarize_with_transformers(article_text, bart_model, bart_tokenizer))\n",
        "    print()\n",
        "\n",
        "    # PEGASUS summarization\n",
        "    pegasus_model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
        "    pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "    print(\"PEGASUS Summary:\", summarize_with_transformers(article_text, pegasus_model, pegasus_tokenizer))\n",
        "    print()\n",
        "\n",
        "    # T5 summarization\n",
        "    t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "    t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "    print(\"T5 Summary:\", summarize_with_transformers(article_text, t5_model, t5_tokenizer))\n",
        "    print()\n",
        "else:\n",
        "    print(\"No content was extracted for summarization.\")"
      ],
      "metadata": {
        "id": "iLVo8wupug2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion <a id=\"conclusion\"></a>"
      ],
      "metadata": {
        "id": "pZK-QKJHuigP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored various text summarization methods in NLP to generate concise summaries from a longer article discussing neural networks. We compared several techniques, including Gensim, Summa, TextRank, LexRank, Luhn, LSA, BART, PEGASUS, and T5.\n",
        "\n",
        "The results demonstrated that each method produced slightly different summaries, highlighting different aspects of the original text. The transformer-based models (BART, PEGASUS, and T5) generally generated more coherent and fluent summaries compared to the traditional extractive methods.\n",
        "\n",
        "However, the effectiveness of each summarization technique may vary depending on the specific text and the desired level of abstractiveness. It is important to consider the trade-offs between summary length, informativeness, and coherence when selecting a summarization method for a particular task.\n",
        "\n",
        "Overall, this exploration provided insights into the capabilities and limitations of different summarization approaches in NLP. Further experimentation and evaluation on a larger corpus of texts would be beneficial to assess the generalizability and robustness of these methods."
      ],
      "metadata": {
        "id": "rqh-l3TcukfY"
      }
    }
  ]
}